{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'numpy.random' has no attribute 'default_rng'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_27841/2568559998.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaggedDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/parsing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401\n\u001b[0m\u001b[1;32m      5\u001b[0m                             \u001b[0mstrip_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_short\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_numeric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                             \u001b[0mstrip_non_alphanum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_multiple_whitespaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/parsing/preprocessing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#: A default, shared numpy-Generator-based PRNG for any/all uses that don't require seeding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mdefault_prng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy.random' has no attribute 'default_rng'"
          ]
        }
      ],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "from PIL import Image, ImageFile\n",
        "import re\n",
        "import nltk\n",
        "import os\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "f-D8Q7P8En9I"
      },
      "outputs": [],
      "source": [
        "#!pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "oNXwGv05En9b",
        "outputId": "1045f7c1-8f25-4ddb-d5e7-d368c4bad580"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "F3s5QLmzZzze"
      },
      "outputs": [],
      "source": [
        "#albums_path = '/Users/Nick/OneDrive/College/2018 Fall/Data Science Lab EE460J/Final Project/output'\n",
        "#output_path = '/Users/Nick/OneDrive/College/2018 Fall/Data Science Lab EE460J/Final Project/embeddings'\n",
        "\n",
        "albums_path = '/home/shezin/Desktop/Lyristic/output'\n",
        "output_path = '/home/shezin/Desktop/Lyristic/emb'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ef8glHjiEn9s"
      },
      "outputs": [],
      "source": [
        "def format_data(albums_path):\n",
        "    all_lyrics = []\n",
        "    \n",
        "    for dirName, subdirList, fileList in os.walk(albums_path, topdown=False):\n",
        "        for fname in fileList:\n",
        "            \n",
        "            if fname.endswith('.txt'):\n",
        "                lyrics_file = open(dirName + '/' + fname, \"r\")\n",
        "                lyrics = lyrics_file.read()\n",
        "                lyrics_file.close()\n",
        "                \n",
        "                \n",
        "                lyrics = lyrics.replace('\\n', ' ')\n",
        "                lyrics = lyrics.replace('\\\\', '')\n",
        "                lyrics = lyrics.strip(' ')\n",
        "                #lyrics = lyrics.replace(r\"\\[.*\\]\",\"\")\n",
        "                lyrics = re.sub(r'\\[[^\\]]*\\]', '', lyrics)\n",
        "                all_lyrics.append(lyrics.lower())\n",
        "                \n",
        "                \n",
        "            if fname.endswith('.jpg'):\n",
        "                #Hidden file issues in colab\n",
        "                resized_img = Image.open(dirName + '/' + fname).resize((256, 256))\n",
        "                resized_img.save(dirName + '/' + fname)\n",
        "            \n",
        "    return all_lyrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_SjjiXMAEn-o",
        "tags": []
      },
      "outputs": [],
      "source": [
        "lyrics = format_data(albums_path)\n",
        "\n",
        "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(lyrics)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-olqY9X3En_G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration 0\n",
            "iteration 1\n",
            "iteration 2\n",
            "iteration 3\n",
            "iteration 4\n",
            "iteration 5\n",
            "iteration 6\n",
            "iteration 7\n",
            "iteration 8\n",
            "iteration 9\n",
            "iteration 10\n",
            "iteration 11\n",
            "iteration 12\n",
            "iteration 13\n",
            "iteration 14\n",
            "iteration 15\n",
            "iteration 16\n",
            "iteration 17\n",
            "iteration 18\n",
            "iteration 19\n",
            "iteration 20\n",
            "iteration 21\n",
            "iteration 22\n",
            "iteration 23\n",
            "iteration 24\n",
            "iteration 25\n",
            "iteration 26\n",
            "iteration 27\n",
            "iteration 28\n",
            "iteration 29\n",
            "iteration 30\n",
            "iteration 31\n",
            "iteration 32\n",
            "iteration 33\n",
            "iteration 34\n",
            "iteration 35\n",
            "iteration 36\n",
            "iteration 37\n",
            "iteration 38\n",
            "iteration 39\n",
            "iteration 40\n",
            "iteration 41\n",
            "iteration 42\n",
            "iteration 43\n",
            "iteration 44\n",
            "iteration 45\n",
            "iteration 46\n",
            "iteration 47\n",
            "iteration 48\n",
            "iteration 49\n",
            "iteration 50\n",
            "iteration 51\n",
            "iteration 52\n",
            "iteration 53\n",
            "iteration 54\n",
            "iteration 55\n",
            "iteration 56\n",
            "iteration 57\n",
            "iteration 58\n",
            "iteration 59\n",
            "iteration 60\n",
            "iteration 61\n",
            "iteration 62\n",
            "iteration 63\n",
            "iteration 64\n",
            "iteration 65\n",
            "iteration 66\n",
            "iteration 67\n",
            "iteration 68\n",
            "iteration 69\n",
            "iteration 70\n",
            "iteration 71\n",
            "iteration 72\n",
            "iteration 73\n",
            "iteration 74\n",
            "iteration 75\n",
            "iteration 76\n",
            "iteration 77\n",
            "iteration 78\n",
            "iteration 79\n",
            "iteration 80\n",
            "iteration 81\n",
            "iteration 82\n",
            "iteration 83\n",
            "iteration 84\n",
            "iteration 85\n",
            "iteration 86\n",
            "iteration 87\n",
            "iteration 88\n",
            "iteration 89\n",
            "iteration 90\n",
            "iteration 91\n",
            "iteration 92\n",
            "iteration 93\n",
            "iteration 94\n",
            "iteration 95\n",
            "iteration 96\n",
            "iteration 97\n",
            "iteration 98\n",
            "iteration 99\n",
            "new Model Saved\n"
          ]
        }
      ],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec\n",
        "max_epochs = 100\n",
        "vec_size = 256\n",
        "alpha = 0.025\n",
        "\n",
        "model = Doc2Vec(vector_size=vec_size,\n",
        "                alpha=alpha, \n",
        "                min_alpha=0.00025,\n",
        "                min_count=1,\n",
        "                dm=1,\n",
        "                epochs=5)\n",
        "  \n",
        "model.build_vocab(tagged_data)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print('iteration {0}'.format(epoch))\n",
        "    model.train(tagged_data,\n",
        "                total_examples=model.corpus_count,\n",
        "                epochs=model.epochs)\n",
        "    # decrease the learning rate\n",
        "    model.alpha -= 0.0002\n",
        "    # fix the learning rate, no decay\n",
        "    model.min_alpha = model.alpha\n",
        "\n",
        "model.save(\"newd2v.model\")\n",
        "print(\"new Model Saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OddPi-R8En_b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "V1_infer [-1.92375656e-03 -2.54958346e-02 -1.96488239e-02  1.15390597e-02\n",
            "  2.83209905e-02  1.59594999e-03  8.15214776e-03  1.27564324e-02\n",
            " -1.82663500e-02  2.43524555e-02  2.06144270e-03 -1.51197379e-02\n",
            "  4.10767924e-03  6.10244693e-03 -1.19378436e-02  9.47892852e-03\n",
            "  1.82248857e-02 -1.10979751e-03 -2.10657883e-02  1.19217988e-02\n",
            " -3.34069203e-03 -2.99571408e-03  5.04342047e-03 -1.54435504e-02\n",
            " -1.61644109e-02 -1.06337364e-03 -5.86290611e-03 -3.74967232e-03\n",
            "  7.27828406e-03 -9.33383126e-03  8.70098919e-03  6.52185362e-03\n",
            "  3.61848576e-03  4.98640351e-04  3.12484102e-03  1.19153401e-02\n",
            "  2.15859171e-02 -4.32068063e-03  2.06008665e-02 -9.53370705e-03\n",
            " -3.29327420e-03  1.81369092e-02  1.13796694e-02 -2.67953537e-02\n",
            "  1.39712729e-02 -9.59111378e-03  8.81327968e-03 -1.32999057e-03\n",
            "  1.18830409e-02  2.72178557e-03 -1.71974767e-03  2.02868897e-02\n",
            "  9.27997660e-03  7.85296876e-03  9.14768409e-03 -1.22201657e-02\n",
            "  4.93466482e-03 -2.73190765e-03  1.84215081e-04  1.18957944e-02\n",
            " -7.30011519e-03 -4.21406701e-03  1.05201686e-02  6.59353472e-03\n",
            "  1.15388930e-02 -1.13290939e-02  1.70133244e-02  1.71491448e-02\n",
            " -1.00258598e-02  6.40968932e-03  4.46152082e-03 -1.28037594e-02\n",
            "  2.79266108e-03 -5.11504151e-03 -2.79967650e-03  6.09961851e-03\n",
            " -1.17271431e-02 -1.03210527e-02 -8.12607352e-03  6.92998618e-03\n",
            " -1.97887830e-02  5.48051624e-03  1.33629458e-03  1.20550888e-02\n",
            " -1.69646256e-02  1.64946038e-02 -8.70608818e-03 -1.91456620e-02\n",
            " -1.45554105e-02  6.41692989e-03  7.89483078e-03 -1.27596250e-02\n",
            "  3.25436657e-03  4.58603632e-03  2.59521604e-03  9.66739375e-03\n",
            " -2.59181149e-02 -7.34239863e-03  1.81166865e-02 -5.53219486e-03\n",
            " -1.66916996e-02 -9.93973948e-03  1.28770084e-03 -1.34585183e-02\n",
            " -3.11001064e-03 -4.18177899e-03 -8.45520664e-03  7.75641005e-04\n",
            "  1.88345239e-02  4.39752173e-03 -5.16343210e-03 -2.82785259e-02\n",
            " -1.52810104e-02 -1.02327496e-03 -1.13837318e-02 -4.97011747e-03\n",
            "  4.83156275e-03  2.23284727e-03  6.38403418e-03  1.68315731e-02\n",
            " -2.07829382e-03 -7.43260141e-03 -3.96872638e-04  3.89466574e-03\n",
            " -3.83372884e-03  1.37711307e-02  3.20706423e-03  1.50908232e-02\n",
            "  2.49291193e-02  2.79920106e-03  1.42297968e-02  9.50293336e-03\n",
            "  5.00164460e-03 -1.05044078e-02 -1.02460189e-02  1.19166505e-02\n",
            " -1.19387009e-03  1.48471221e-02 -2.12151557e-03  3.11127189e-03\n",
            "  1.04491906e-02  1.08465720e-02  5.09195030e-03  6.61952421e-03\n",
            " -2.02805474e-02 -1.10216271e-02 -2.14297548e-02 -1.01696164e-03\n",
            "  1.46147935e-03 -9.78191383e-05 -6.49262685e-03 -7.14683905e-03\n",
            "  3.48601234e-03  2.60252948e-03 -7.14578247e-03  2.05793865e-02\n",
            "  8.27620551e-03  1.25578856e-02 -9.76380892e-03  3.57002486e-03\n",
            " -2.67313374e-03  2.08241865e-02  3.76898656e-03  9.33138840e-03\n",
            "  1.14244688e-03  9.26833414e-03  1.29259261e-03  4.91150375e-03\n",
            " -2.76352675e-03 -3.14889476e-04  5.11367619e-03  1.29386680e-02\n",
            " -4.65240970e-04  1.10845652e-03 -1.79652870e-02  7.51666166e-03\n",
            " -3.19570154e-02 -3.08490125e-03  1.13339154e-02  2.26353537e-02\n",
            "  7.65529368e-03  7.22736306e-03  1.66886579e-02 -1.28951427e-02\n",
            "  2.55475659e-03  1.83622744e-02 -2.06020903e-02 -1.03173666e-02\n",
            " -1.22312997e-02  5.31718833e-03  1.41966185e-02 -7.35764485e-03\n",
            " -1.11333486e-02 -6.68295333e-03  4.10263147e-03 -4.84000705e-03\n",
            "  5.53326448e-04 -7.64382677e-03 -4.19087755e-03 -1.10187596e-02\n",
            " -2.10695453e-02  1.38498889e-02  2.08703391e-02 -9.56869801e-04\n",
            "  1.72355236e-03 -1.26322079e-02 -1.38308480e-03 -6.14421349e-03\n",
            " -1.89483128e-02 -8.82967375e-03  6.97802380e-03 -6.24128792e-04\n",
            "  1.59318023e-03  9.53957625e-03  2.61912867e-02 -7.19131203e-04\n",
            "  3.04116658e-03  9.57399234e-03  8.87585524e-03  7.19366223e-03\n",
            "  4.67534037e-03  1.15354070e-02 -3.79289198e-03 -2.31329887e-03\n",
            "  5.18016610e-03 -6.14679186e-04 -6.87080575e-03  9.52511840e-03\n",
            "  3.85105447e-03 -1.06122782e-02  3.34542128e-03 -2.33672885e-03\n",
            " -5.42933005e-04  1.32776089e-02 -4.41705156e-03  1.06331706e-02\n",
            " -1.14485379e-02 -1.35992616e-02  9.08181444e-03  2.96626473e-03\n",
            "  7.92922825e-03 -4.03175037e-03  6.92408532e-03 -6.07288256e-03\n",
            " -1.80258311e-03  1.47886211e-02 -1.95096701e-03  5.25344396e-04\n",
            " -1.07824123e-02  2.34550051e-03 -2.47328682e-03  3.16997082e-03\n",
            " -1.90836936e-03  2.60995794e-03 -6.08361699e-03 -5.57468832e-03]\n",
            "[('46', 0.508030354976654), ('53', 0.5055704712867737), ('3', 0.4960106909275055), ('52', 0.4697036147117615), ('10', 0.4476514458656311), ('21', 0.4451242983341217), ('56', 0.4387895166873932), ('5', 0.4280183017253876), ('13', 0.4250442683696747), ('2', 0.42467838525772095)]\n",
            "[ 1.3700233  -2.6028054   0.8537271   1.5859073   3.757541    0.58598906\n",
            "  0.23975101 -1.2227803  -0.93041563  0.6105706  -0.6958299   1.0254911\n",
            "  1.8026838  -1.2580345  -2.1516778   3.2893145  -0.6722023   1.1997155\n",
            "  0.49142757  0.25931284  0.45097008 -0.13300893 -2.0721374  -1.644998\n",
            " -4.311199   -1.8961538  -1.6061299   0.07423507 -1.4472684  -1.3342767\n",
            " -1.1385697  -2.137709   -1.1454844   1.7376385  -1.4598291   0.34084618\n",
            "  0.4686667  -0.5400849   0.7315093   1.3419956  -0.36973023 -0.6494739\n",
            "  2.8189805  -2.1258307   0.72091764  2.325981    2.8612523   1.8478435\n",
            "  0.5987868   0.3179104  -2.541261    1.9171019   0.83630204  0.21864276\n",
            "  1.0981234  -2.609546    0.18352392  2.0860913   0.5237461   3.5887063\n",
            " -0.14259188  2.203131   -0.17214477 -0.4331933   0.19100606  1.1237056\n",
            "  0.3657664   1.7993668  -0.74819654  0.6932763  -1.8569111  -0.9554504\n",
            " -1.1791662  -1.717429   -0.54894465  1.9436208  -0.76190895 -2.3062246\n",
            "  1.407419   -0.6055722  -0.20216988 -1.7067848   0.9032445   2.3107848\n",
            " -1.5823876   1.166034   -0.10639996  0.10799305 -2.4895191  -0.74487585\n",
            " -3.9283607   1.450913    0.11678792 -0.5383877  -1.7412609   0.69500476\n",
            " -0.9241996   1.2597944  -1.4797785  -0.68800044 -3.6266997   3.4255066\n",
            "  1.6576351   0.8132565   0.61922723  0.7377153   1.9791405   0.6225948\n",
            "  2.800279    1.1300876   1.0103562  -1.8302801   1.1115385  -0.31925553\n",
            " -0.23555842 -0.3916347   0.51837504  0.3581765   1.3938022   0.48610818\n",
            " -0.4306248  -2.460408    0.59091663  1.1467963  -0.78208256  0.09344047\n",
            " -1.681679    1.0654397  -0.4397834   0.25622833  1.3436018   0.07655059\n",
            "  0.3812512  -2.0664494  -2.1953397   0.4502081   0.78150374  0.27001747\n",
            "  0.43352324  0.28000492 -0.2370349   0.8445471   2.7499993   1.227884\n",
            " -1.710222   -2.507761   -0.42676204  0.6872379  -2.120865    0.31446594\n",
            " -3.508789    1.4799924   1.7838508   0.88185006 -0.83842635 -0.11494347\n",
            "  0.42118782  3.1275632  -1.0616498   1.0286322  -1.1224182   1.6351756\n",
            "  0.89152455 -1.1904083  -0.02003531  0.2870361   2.6880894  -1.1427842\n",
            " -0.96949327  0.29352203  1.9310426   0.2717006  -0.16430429  0.05202579\n",
            " -0.29773024  1.5910696  -2.6194887   1.4200897   0.66116285  2.3995087\n",
            " -1.4539386  -2.1641061   2.1351268  -0.5474905  -0.40846884  2.500332\n",
            " -1.5310897  -0.06468805 -2.7178626   0.37748668  1.3951421  -1.4080462\n",
            " -0.68067724 -0.8732362   1.6475375  -0.9842362   1.1230356  -1.0339227\n",
            " -2.4306512  -1.7695124  -0.75343037 -0.67501426  0.8156859  -2.5496678\n",
            "  0.25729856  0.05329887 -1.3331162   0.98510736  0.22270118 -1.3809215\n",
            " -1.4756312   2.178837    0.83897877  1.3691071   0.27071938 -0.23448913\n",
            " -0.5271002   1.1013923  -0.31827736  0.46784583 -2.8962398  -1.1894057\n",
            " -0.47114548 -2.120959    0.07280568  0.1770337  -1.4286313  -1.6379457\n",
            "  0.74080455 -2.1174092  -1.2120302  -2.028137    0.44912094  1.7835772\n",
            " -1.998531    2.2101738  -0.39173463 -0.2699688   0.5934669  -0.21338925\n",
            " -1.542106    3.275223   -0.33909896 -1.7173961  -2.8231814  -2.3655703\n",
            "  2.0611348   0.84490925 -1.3376096   1.1575792   0.48083758  1.0212232\n",
            " -1.6599675  -2.8148248  -2.4982622   0.742821  ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-11378e74a7b1>:11: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
            "  similar_doc = model.docvecs.most_similar('1')\n",
            "<ipython-input-10-11378e74a7b1>:16: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
            "  print(model.docvecs['1'])\n"
          ]
        }
      ],
      "source": [
        "# from gensim.models.doc2vec import Doc2Vec\n",
        "\n",
        "# model= Doc2Vec.load(\"newd2v.model\")\n",
        "\n",
        "# #to find the vector of a document which is not in training data\n",
        "# test_data = word_tokenize(\"Smells like teen spirit\".lower())\n",
        "# v1 = model.infer_vector(test_data)\n",
        "# print(\"V1_infer\", v1)\n",
        "\n",
        "# # to find most similar doc using tags\n",
        "# similar_doc = model.docvecs.most_similar('1')\n",
        "# print(similar_doc)\n",
        "\n",
        "\n",
        "# # to find vector of doc in training data using tags or in other words, printing the vector of document at index 1 in training data\n",
        "# print(model.docvecs['1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9pmsLZa2En_8"
      },
      "outputs": [],
      "source": [
        "def output_embeddings(output_path, albums_path):\n",
        "    embeddings = {}\n",
        "    \n",
        "    for dirName, subdirList, fileList in os.walk(albums_path, topdown=False):\n",
        "        album_lyrics = ''\n",
        "        album_name = dirName.split('/')[-1]\n",
        "        \n",
        "        for fname in fileList:\n",
        "            \n",
        "            if fname.endswith('.txt'):\n",
        "                lyrics_file = open(dirName + '/' + fname, \"r\")\n",
        "                lyrics = lyrics_file.read()\n",
        "                lyrics_file.close()\n",
        "                \n",
        "                \n",
        "                lyrics = lyrics.replace('\\n', ' ')\n",
        "                lyrics = lyrics.replace('\\\\', '')\n",
        "                lyrics = lyrics.strip(' ')\n",
        "                lyrics = re.sub(r'\\[[^\\]]*\\]', '', lyrics)\n",
        "                album_lyrics = album_lyrics + lyrics.lower() + ' '\n",
        "        \n",
        "        if not len(album_lyrics) == 0:\n",
        "            temp = word_tokenize(album_lyrics)\n",
        "            vector = model.infer_vector(temp)\n",
        "            embeddings[album_name.replace('/','-')] = vector\n",
        "    \n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oh25XM3ZEoAH"
      },
      "outputs": [],
      "source": [
        "embeddings = output_embeddings(output_path, albums_path)\n",
        "\n",
        "#print(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "CDjEi6fHEoAU"
      },
      "outputs": [],
      "source": [
        "file = \"new_embeddings\"\n",
        "\n",
        "file_object = open(file,'wb')\n",
        "\n",
        "pickle.dump(embeddings, file_object)\n",
        "\n",
        "file_object.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "vectorize_input.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "interpreter": {
      "hash": "e5030792b3492f6b12d94f1f48beca3d8e59ec05fd59d0aaaa48e684281ed297"
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}